{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30219f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MANIKA\\AppData\\Local\\Temp\\ipykernel_12800\\1539622755.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neighbors import KNeighborsClassifier   \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0980ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "624c5009-55b4-402b-938c-94e84113759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impFeature(indep_X,dep_Y,n):\n",
    "        implist=[]\n",
    "        featurexgb = XGBClassifier()\n",
    "        RF = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "        importFeature_lasso=Lasso(alpha=0.1)\n",
    "     \n",
    "        impmodellist=[featurexgb,RF,importFeature_lasso] \n",
    "       \n",
    "        for i in impmodellist:\n",
    "            print(i)\n",
    "            log_imp = permutation_importance(estimator=i, n_features_to_select=n)\n",
    "            log_fit = log_imp.fit(indep_X, dep_Y)\n",
    "            log_imp_feature=log_fit.transform(indep_X)\n",
    "            implist.append(log_imp_feature)\n",
    "        return implist\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e950659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_scalar(indep_X,dep_Y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(indep_X, dep_Y, test_size = 0.25, random_state = 0)\n",
    "        #X_train, X_test, y_train, y_test = train_test_split(indep_X,dep_Y, test_size = 0.25, random_state = 0)\n",
    "        \n",
    "        #Feature Scaling\n",
    "        #from sklearn.preprocessing import StandardScaler\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "def cm_prediction(classifier,X_test):\n",
    "     y_pred = classifier.predict(X_test)\n",
    "        \n",
    "        # Making the Confusion Matrix\n",
    "     from sklearn.metrics import confusion_matrix\n",
    "     cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "     from sklearn.metrics import accuracy_score \n",
    "     from sklearn.metrics import classification_report \n",
    "        #from sklearn.metrics import confusion_matrix\n",
    "        #cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "     Accuracy=accuracy_score(y_test, y_pred )\n",
    "        \n",
    "     report=classification_report(y_test, y_pred)\n",
    "     return  classifier,Accuracy,report,X_test,y_test,cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a90f4295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(X_train,y_train,X_test):\n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        classifier = LogisticRegression(random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm      \n",
    "    \n",
    "def svm_linear(X_train,y_train,X_test):\n",
    "                \n",
    "        from sklearn.svm import SVC\n",
    "        classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm\n",
    "    \n",
    "def svm_NL(X_train,y_train,X_test):\n",
    "                \n",
    "        from sklearn.svm import SVC\n",
    "        classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm\n",
    "   \n",
    "def Navie(X_train,y_train,X_test):       \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.naive_bayes import GaussianNB\n",
    "        classifier = GaussianNB()\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm         \n",
    "    \n",
    "    \n",
    "def knn(X_train,y_train,X_test):\n",
    "           \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm\n",
    "def Decision(X_train,y_train,X_test):\n",
    "        \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm      \n",
    "\n",
    "\n",
    "def random(X_train,y_train,X_test):\n",
    "        \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d83a0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imp_classification(acclog,accsvml,accsvmnl,accknn,accnav,accdes,accrf): \n",
    "    \n",
    "    impdataframe=pd.DataFrame(index=['importFeaturexgb','RF','importFeature_lasso'],columns=['Logistic','SVMl','SVMnl',\n",
    "                                                                                        'KNN','Navie','Decision','Random'])\n",
    "\n",
    "    for number,idex in enumerate(impdataframe.index):\n",
    "        \n",
    "        impdataframe['Logistic'][idex]=acclog[number]       \n",
    "        impdataframe['SVMl'][idex]=accsvml[number]\n",
    "        impdataframe['SVMnl'][idex]=accsvmnl[number]\n",
    "        impdataframe['KNN'][idex]=accknn[number]\n",
    "        impdataframe['Navie'][idex]=accnav[number]\n",
    "        impdataframe['Decision'][idex]=accdes[number]\n",
    "        impdataframe['Random'][idex]=accrf[number]\n",
    "    return impdataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7719730",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = pd.read_csv(\"prep.csv\", index_col=None)\n",
    "df2 = dataset1\n",
    "df2 = pd.get_dummies(df2, drop_first=True)\n",
    "\n",
    "indep_X = df2.drop('classification_yes', axis=1)\n",
    "dep_Y = df2['classification_yes']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42024818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "missing a required argument: 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m implist\u001b[38;5;241m=\u001b[39mimpFeature(indep_X,dep_Y,\u001b[38;5;241m5\u001b[39m)       \n\u001b[0;32m      3\u001b[0m acclog\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m      4\u001b[0m accsvml\u001b[38;5;241m=\u001b[39m[]\n",
      "Cell \u001b[1;32mIn[3], line 11\u001b[0m, in \u001b[0;36mimpFeature\u001b[1;34m(indep_X, dep_Y, n)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m impmodellist:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m---> 11\u001b[0m     log_imp \u001b[38;5;241m=\u001b[39m permutation_importance(estimator\u001b[38;5;241m=\u001b[39mi, n_features_to_select\u001b[38;5;241m=\u001b[39mn)\n\u001b[0;32m     12\u001b[0m     log_fit \u001b[38;5;241m=\u001b[39m log_imp\u001b[38;5;241m.\u001b[39mfit(indep_X, dep_Y)\n\u001b[0;32m     13\u001b[0m     log_imp_feature\u001b[38;5;241m=\u001b[39mlog_fit\u001b[38;5;241m.\u001b[39mtransform(indep_X)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:191\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n\u001b[1;32m--> 191\u001b[0m params \u001b[38;5;241m=\u001b[39m func_sig\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    192\u001b[0m params\u001b[38;5;241m.\u001b[39mapply_defaults()\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# ignore self/cls and positional/keyword markers\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\iml\\Lib\\inspect.py:3212\u001b[0m, in \u001b[0;36mSignature.bind\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   3208\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[0;32m   3209\u001b[0m \u001b[38;5;124;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[0;32m   3210\u001b[0m \u001b[38;5;124;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[0;32m   3211\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bind(args, kwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\iml\\Lib\\inspect.py:3182\u001b[0m, in \u001b[0;36mSignature._bind\u001b[1;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[0;32m   3175\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m   3176\u001b[0m     \u001b[38;5;66;03m# We have no value for this parameter.  It's fine though,\u001b[39;00m\n\u001b[0;32m   3177\u001b[0m     \u001b[38;5;66;03m# if it has a default value, or it is an '*args'-like\u001b[39;00m\n\u001b[0;32m   3178\u001b[0m     \u001b[38;5;66;03m# parameter, left alone by the processing of positional\u001b[39;00m\n\u001b[0;32m   3179\u001b[0m     \u001b[38;5;66;03m# arguments.\u001b[39;00m\n\u001b[0;32m   3180\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m partial \u001b[38;5;129;01mand\u001b[39;00m param\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m!=\u001b[39m _VAR_POSITIONAL \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m   3181\u001b[0m                                         param\u001b[38;5;241m.\u001b[39mdefault \u001b[38;5;129;01mis\u001b[39;00m _empty):\n\u001b[1;32m-> 3182\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing a required argument: \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39m \\\n\u001b[0;32m   3183\u001b[0m                         \u001b[38;5;28mformat\u001b[39m(arg\u001b[38;5;241m=\u001b[39mparam_name)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m _POSITIONAL_ONLY:\n\u001b[0;32m   3187\u001b[0m         \u001b[38;5;66;03m# This should never happen in case of a properly built\u001b[39;00m\n\u001b[0;32m   3188\u001b[0m         \u001b[38;5;66;03m# Signature object (but let's have this check here\u001b[39;00m\n\u001b[0;32m   3189\u001b[0m         \u001b[38;5;66;03m# to ensure correct behaviour just in case)\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: missing a required argument: 'X'"
     ]
    }
   ],
   "source": [
    "implist=impFeature(indep_X,dep_Y,5)       \n",
    "\n",
    "acclog=[]\n",
    "accsvml=[]\n",
    "accsvmnl=[]\n",
    "accknn=[]\n",
    "accnav=[]\n",
    "accdes=[]\n",
    "accrf=[]\n",
    "\n",
    "for i in implist:   \n",
    "    X_train, X_test, y_train, y_test=split_scalar(i,dep_Y)   \n",
    "    \n",
    "        \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=logistic(X_train,y_train,X_test)\n",
    "    acclog.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=svm_linear(X_train,y_train,X_test)  \n",
    "    accsvml.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=svm_NL(X_train,y_train,X_test)  \n",
    "    accsvmnl.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=knn(X_train,y_train,X_test)  \n",
    "    accknn.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=Navie(X_train,y_train,X_test)  \n",
    "    accnav.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=Decision(X_train,y_train,X_test)  \n",
    "    accdes.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=random(X_train,y_train,X_test)  \n",
    "    accrf.append(Accuracy)\n",
    "    \n",
    "result=imp_classification(acclog,accsvml,accsvmnl,accknn,accnav,accdes,accrf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
